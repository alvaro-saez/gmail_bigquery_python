{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "388d49d6-fd0d-447d-a96f-0dba8e4ab5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import LoadJobConfig\n",
    "from pandas_gbq import to_gbq\n",
    "import pandas as pd\n",
    "\n",
    "from google_auth_oauthlib import flow #para hacerlo con la autentifiacion de cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e71c824-5711-4d14-942b-2bf6bad07906",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "bq_credentials = './credenciales/client_secret_python_bq.json'\n",
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'bigquery-public-data'\n",
    "table_id = 'ga4_obfuscated_sample_ecommerce.events_20210131'\n",
    "#table_ref = client.dataset(dataset_id).table(table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef08560-644c-4873-b4b6-83d460ded227",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(bq_credentials, scopes=scopes)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f022ff4-54b8-4562-9839-3fa5069103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query de ejemplo\n",
    "query_ejemplo = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `{}.{}`\n",
    "    Limit 10\n",
    "\"\"\".format(dataset_id,table_id)\n",
    "\n",
    "query_ejecutada_ejemplo = client.query(query_ejemplo)\n",
    "resultado_ejemplo = query_ejecutada_ejemplo.result()\n",
    "\n",
    "#for row_ejemplo in resultado_ejemplo:\n",
    "#    print(row_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c06cd1a-133e-4304-889a-a6ceef9d931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear la tabla si no existe\n",
    "query1 = \"\"\"\n",
    "    CREATE SCHEMA IF NOT EXISTS `{}.{}`(\n",
    "        columna1 TIPO_DE_DATO1,\n",
    "        columna2 TIPO_DE_DATO2,\n",
    "    ...\n",
    "    )\n",
    "    PARTITION BY fecha;\n",
    "\"\"\".format(dataset_id,table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be55ce7d-61cf-4621-be63-bda89c8fb20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#insertar valores en la tabla (¿sustituimos los valores existentes o los añadimods)\n",
    "query2 = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `{}.{}`\n",
    "\"\"\".format(dataset_id,table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757f697-6d0c-43c6-ae5a-573a8b8639a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [query1, query2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada1b49-1b63-4bc6-a5d7-f9a372231739",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_i in query_list:\n",
    "    query_i_ejecuted = client.query(query_i)\n",
    "    result_query_i = query_i_ejecuted.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7f7d1-df65-4d65-b442-87b2f330848e",
   "metadata": {},
   "source": [
    "-----------\n",
    "#### CREAR TABLA E INSERTAR DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3667c-bbfe-46f8-86a1-99985fdd1e06",
   "metadata": {},
   "source": [
    "##### a) con query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "678edbeb-6dfc-4ac5-8a26-5193feb9b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'chicago_taxi_tips'\n",
    "table_id = 'cars_upload_test'\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(bq_credentials, scopes=scopes)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226b815-99b2-419b-8444-2928e54de76d",
   "metadata": {},
   "source": [
    "##### b) a mano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df89869-5faf-487f-a83b-f54117bf177a",
   "metadata": {},
   "source": [
    "###### 1.A crear la tabla a mano si no existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b163040-3294-4d73-a30d-76257adf5e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test no existe en el conjunto de datos chicago_taxi_tips.\n",
      "Created table curso-bigquery-mide-403114.chicago_taxi_tips.cars_upload_test\n"
     ]
    }
   ],
   "source": [
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'chicago_taxi_tips'\n",
    "table_id = 'cars_upload_test'\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(bq_credentials, scopes=scopes)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} ya existe en el conjunto de datos {dataset_id}.\")\n",
    "except Exception as e:\n",
    "    if \"Not found\" in str(e):\n",
    "        print(f\"La tabla {table_id} no existe en el conjunto de datos {dataset_id}.\")\n",
    "        # Crea la tabla si no existe\n",
    "        schema = [\n",
    "            bigquery.SchemaField(\"cars\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"mpg\", \"FLOAT\", mode=\"REQUIRED\"),\n",
    "            bigquery.SchemaField(\"cyl\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"disp\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"hp\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"drat\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"wt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"qsec\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"vs\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"am\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"gear\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"carb\", \"INTEGER\", mode=\"NULLABLE\")\n",
    "        ]\n",
    "        table = bigquery.Table(table_ref, schema=schema)\n",
    "        table = client.create_table(table)\n",
    "        print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n",
    "    else:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909c780-6e75-49f8-9a31-45d2f9e61bab",
   "metadata": {},
   "source": [
    "###### 1.B crear la tabla leyendo el schema del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f92349e-f889-4e3e-b224-9d91d4b9fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table curso-bigquery-mide-403114.chicago_taxi_tips.cars_upload_test\n",
      "Esquema inferido para la tabla cars_upload_test: {'cars': 'STRING', 'mpg': 'FLOAT', 'cyl': 'FLOAT', 'disp': 'FLOAT', 'hp': 'FLOAT', 'drat': 'FLOAT', 'wt': 'FLOAT', 'qsec': 'FLOAT', 'vs': 'FLOAT', 'am': 'FLOAT', 'gear': 'FLOAT', 'carb': 'FLOAT'}\n"
     ]
    }
   ],
   "source": [
    "csv_path = './files/cars.csv'\n",
    "\n",
    "# Crea una instancia de la tabla en BigQuery (no la crea, solo define el esquema)\n",
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'chicago_taxi_tips'\n",
    "table_id = 'cars_upload_test'\n",
    "\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "# Carga una muestra del CSV en un DataFrame de Pandas\n",
    "sample_df = pd.read_csv(csv_path, sep=\",\", index_col=False)  # Puedes ajustar el número de filas según tu necesidad\n",
    "\n",
    "# Crea un diccionario para almacenar el esquema inferido\n",
    "schema = {}\n",
    "\n",
    "# Itera sobre las columnas y determina el tipo de datos\n",
    "for column in sample_df.columns:\n",
    "    # Infiera el tipo de datos basándose en los tipos de pandas\n",
    "    if pd.api.types.is_string_dtype(sample_df[column]):\n",
    "        schema[column] = 'STRING'\n",
    "    elif pd.api.types.is_numeric_dtype(sample_df[column]):\n",
    "        schema[column] = 'FLOAT'  # Puedes ajustar según sea necesario\n",
    "    else:\n",
    "        schema[column] = 'STRING'  # Puedes ajustar según sea necesario\n",
    "\n",
    "# iterar este esquema para crear el formato qeu BQ necesita en un listado (ejemplo mas arriba en la creacion a mano del listado)\n",
    "schema2=[bigquery.SchemaField(keyx, valuex, mode=\"NULLABLE\") for keyx,valuex in schema.items()]\n",
    "\n",
    "table = bigquery.Table(table_ref, schema=schema2)\n",
    "table = client.create_table(table)\n",
    "print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n",
    "\n",
    "# Configura el esquema de la tabla\n",
    "#table = bigquery.Table(table_ref, schema=[bigquery.SchemaField(column, schema[column]) for column in schema])\n",
    "\n",
    "# Imprime el esquema\n",
    "print(f\"Esquema inferido para la tabla {table_id}: {schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d87eb6-f382-4a05-a093-9751674f2f40",
   "metadata": {},
   "source": [
    "###### 2.A INSERTAR datos del csv en la tabla debajo de los ya existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2c9bbcb-b645-46eb-8ec7-3041e0085d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test existe en el conjunto de datos chicago_taxi_tips.\n",
      "Datos del CSV cargados en la tabla cars_upload_test de BigQuery.\n"
     ]
    }
   ],
   "source": [
    "#cargar datos una vez que ya existe (los inserta debajo, si queremos sustituir, habrá que eliminarlos antes)\n",
    "csv_path ='./files/cars.csv'\n",
    "\n",
    "# Carga el CSV en un DataFrame de Pandas\n",
    "df = pd.read_csv(csv_path, sep=\",\", index_col=False)\n",
    "\n",
    "# Crea una instancia de la tabla en BigQuery (está hecho arriba, si lo hacemos junto habrá que eliminar las 2 siguientes lineas))\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "table = bigquery.Table(table_ref)\n",
    "\n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} existe en el conjunto de datos {dataset_id}.\")\n",
    "\n",
    "    job = client.load_table_from_dataframe(df, table)\n",
    "    job.result()  # Espera a que se complete la carga\n",
    "\n",
    "    print(f\"Datos del CSV cargados en la tabla {table_id} de BigQuery.\")\n",
    "except:\n",
    "    print(f\"La tabla {table_id} NO existe en el conjunto de datos {dataset_id}, hay que crearla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc4264-b0c5-495f-9aec-7725d824ddb1",
   "metadata": {},
   "source": [
    "###### 2.B REEMPLAZAR datos ya existentes en la tabla por los del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b4ab0d-efb5-4ace-b715-95bc8e0de0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test existe en el conjunto de datos chicago_taxi_tips.\n",
      "Datos del CSV reemplazaron los existentes en la tabla cars_upload_test de BigQuery.\n"
     ]
    }
   ],
   "source": [
    "#cargar datos una vez que ya existe (los inserta debajo, si queremos sustituir, habrá que eliminarlos antes)\n",
    "csv_path ='./files/cars.csv'\n",
    "\n",
    "# Carga el CSV en un DataFrame de Pandas\n",
    "df = pd.read_csv(csv_path, sep=\",\", index_col=False)\n",
    "\n",
    "# Crea una instancia de la tabla en BigQuery (está hecho arriba, si lo hacemos junto habrá que eliminar las 2 siguientes lineas))\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "table = bigquery.Table(table_ref)\n",
    "\n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} existe en el conjunto de datos {dataset_id}.\")\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "    job = client.load_table_from_dataframe(df, table, job_config=job_config)\n",
    "    job.result()  # Espera a que se complete la carga\n",
    "\n",
    "    print(f\"Datos del CSV reemplazaron los existentes en la tabla {table_id} de BigQuery.\")\n",
    "\n",
    "except:\n",
    "    print(f\"La tabla {table_id} NO existe en el conjunto de datos {dataset_id}, hay que crearla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333458e-ed88-4cba-b9b0-888ee412b424",
   "metadata": {},
   "source": [
    "##### c) pandas_gbq  -> requiere autenticación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddaf21dc-d2e4-4160-898a-eaf51678b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test ya existe en el conjunto de datos chicago_taxi_tips.\n"
     ]
    }
   ],
   "source": [
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'chicago_taxi_tips'\n",
    "table_id = 'cars_upload_test'\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(bq_credentials, scopes=scopes)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "# Ruta al archivo CSV en tu sistema local\n",
    "csv_path = './files/cars.csv'  # Reemplaza con tu ruta real\n",
    "\n",
    "# Verifica si la tabla existe en el conjunto de datos\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} ya existe en el conjunto de datos {dataset_id}.\")\n",
    "except Exception as e:\n",
    "    if \"Not found\" in str(e):\n",
    "        print(f\"La tabla {table_id} no existe en el conjunto de datos {dataset_id}.\")\n",
    "\n",
    "        # Carga el CSV en un DataFrame de Pandas\n",
    "        df = pd.read_csv(csv_path, sep=\",\", index_col=False)\n",
    "\n",
    "        # Carga el DataFrame en BigQuery\n",
    "        to_gbq(df, f'{project_id}.{dataset_id}.{table_id}', project_id=project_id, if_exists='replace')\n",
    "\n",
    "        print(f\"La tabla {table_id} ha sido creada y los datos del CSV han sido cargados en BigQuery.\")\n",
    "    else:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
