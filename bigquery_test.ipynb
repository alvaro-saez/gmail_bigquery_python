{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "388d49d6-fd0d-447d-a96f-0dba8e4ab5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import LoadJobConfig\n",
    "from pandas_gbq import to_gbq\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "from google_auth_oauthlib import flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f6e30-5cb0-4682-80ee-aec66a465d44",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eedc163a-2cb6-4a4c-be96-448911e748f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "bq_credentials = './credenciales/client_secret_python_bq.json'\n",
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'bigquery-public-data'\n",
    "table_id = 'ga4_obfuscated_sample_ecommerce.events_20210131'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bef08560-644c-4873-b4b6-83d460ded227",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(bq_credentials, scopes=scopes)\n",
    "    client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "except Exception as e:\n",
    "    print(\"Big query conection wrong: \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7f022ff4-54b8-4562-9839-3fa5069103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query de ejemplo\n",
    "query_ejemplo = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `{}.{}`\n",
    "    Limit 10\n",
    "\"\"\".format(dataset_id,table_id)\n",
    "\n",
    "query_ejecutada_ejemplo = client.query(query_ejemplo)\n",
    "resultado_ejemplo = query_ejecutada_ejemplo.result()\n",
    "\n",
    "#for row_ejemplo in resultado_ejemplo:\n",
    "#    print(row_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7f7d1-df65-4d65-b442-87b2f330848e",
   "metadata": {},
   "source": [
    "-----------\n",
    "#### CREAR TABLA E INSERTAR DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d2dee-64fe-4172-be13-92c0b8daada4",
   "metadata": {},
   "source": [
    "#### configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "50a020ff-2cf5-45e4-a86d-e32ec7edc1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLES\n",
    "scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "bq_credentials = './credenciales/client_secret_python_bq.json'\n",
    "\n",
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'chicago_taxi_tips'\n",
    "table_id = 'cars_upload_test'\n",
    "csv_path = './files/cars.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "015f8d63-63ab-4037-a162-68eb082ea6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONEXION\n",
    "def bq_client(scopes, bq_credentials, project_id):\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_file(bq_credentials, scopes=scopes)\n",
    "        client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(\"Big query conection wrong: \" + str(e))\n",
    "\n",
    "client = bq_client(scopes, bq_credentials, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dc9a0496-59f9-43b9-a3fb-8f8d6188486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REFERENCIAR LA TABLA\n",
    "def bq_table_ref(client,dataset_id,table_id):\n",
    "    try:\n",
    "        table_ref = client.dataset(dataset_id).table(table_id)\n",
    "        return table_ref\n",
    "    except Exception as e:\n",
    "        print(\"Error in Bigquery table reference: \" + str(e))\n",
    "\n",
    "bq_table_ref = bq_table_ref(client,dataset_id,table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1fbf1808-3043-4b9f-948d-ec44df709913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV a un DataFrame de Pandas\n",
    "def bq_csv_to_pandas(csv_path):\n",
    "    try:\n",
    "        bigquery_csv = pd.read_csv(csv_path, sep=\",\")\n",
    "        return bigquery_csv\n",
    "    except Exception as e:\n",
    "        print(\"Error importing the csv file\" + str(e))\n",
    "\n",
    "bq_csv_df = bq_csv_to_pandas(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3667c-bbfe-46f8-86a1-99985fdd1e06",
   "metadata": {},
   "source": [
    "##### a) SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fd6f8fad-f61c-4fe5-b211-253484f537d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correr después de crear la query:\n",
    "def bq_query_execution(client, query, dataset_id, table_id):\n",
    "    try:\n",
    "        query_ejecutada = client.query(query)\n",
    "        resultado_query = query_ejecutada.result()\n",
    "\n",
    "        if \"CREATE TABLE\" in query:\n",
    "            return(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n",
    "        elif \"INSERT\" in query:\n",
    "            return(\"Values inserted into {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n",
    "        elif \"TRUNCATE TABLE\" in query:\n",
    "            return(\"TRUNCATE {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c636fbd8-deb2-47e2-bdcb-7b742f775387",
   "metadata": {},
   "source": [
    "###### 1.A crear la tabla si no existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ab7fdbd0-b01a-4abf-97a9-8f50556aaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAR ESQUEMA DESDE EL CSV \n",
    "\n",
    "def bq_schema_for_query(bq_csv_df):\n",
    "    schema_for_query = {}\n",
    "\n",
    "    # Itera sobre las columnas y determina el tipo de datos\n",
    "    try:\n",
    "        for column in bigquery_csv_df.columns:\n",
    "            # Infiere el tipo de datos basándose en los tipos de pandas\n",
    "            if pd.api.types.is_string_dtype(bq_csv_df[column]):\n",
    "                schema_for_query[column] = 'STRING'\n",
    "            elif pd.api.types.is_numeric_dtype(bq_csv_df[column]):\n",
    "                if pd.api.types.is_float_dtype(bq_csv_df[column]):\n",
    "                    schema_for_query[column] = 'FLOAT'\n",
    "                else:\n",
    "                    schema_for_query[column] = 'INTEGER'\n",
    "            else:\n",
    "                schema_for_query[column] = 'STRING'\n",
    "                \n",
    "        schema_for_query = re.sub(\"'|\\{|\\}|\\[|\\]|\\:\",\"\",str(schema))\n",
    "        schema_for_query = re.sub(\"FLOAT\",\"FLOAT64\",str(schema_for_query))\n",
    "        schema_for_query = re.sub(\"INTEGER\",\"INT64\",str(schema_for_query))\n",
    "\n",
    "        return schema_for_query\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "bq_schema_for_query = bq_schema_for_query(bigquery_csv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8a951500-4f80-4997-854b-58b79dd687dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear la tabla si no existe --> https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language\n",
    "def bq_query_create_table(dataset_id,table_id,bq_schema_for_query):\n",
    "    query = \"\"\"CREATE TABLE IF NOT EXISTS `{}.{}`({});\"\"\".format(dataset_id,table_id,bq_schema_for_query)\n",
    "    return query\n",
    "    \n",
    "    #PARTITION BY fecha\n",
    "    #OPTIONS(\n",
    "    #    partition_expiration_days=100,\n",
    "    #    description=\"a table partitioned by fecha\");\n",
    "\n",
    "bq_query_create_table = bq_query_create_table(dataset_id,table_id,bq_schema_for_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "90917f9f-a1d2-4600-9233-58abe3cd70bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Created table curso-bigquery-mide-403114.chicago_taxi_tips.cars_upload_test'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ejecución de la query\n",
    "bq_query_execution(client, bq_query_create_table, dataset_id, table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87f4d2-fac0-487a-b7ff-acbd50f9b536",
   "metadata": {},
   "source": [
    "###### 2.A INSERTAR datos del csv en la tabla debajo de los ya existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "67f45fde-766c-47ef-a367-984a24ebf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_query_insert_values(bq_csv_df,dataset_id,table_id):\n",
    "    #crear columnas\n",
    "    columns_for_query = list(bq_csv_df.columns)\n",
    "    columns_for_query = re.sub(\"'|\\{|\\}|\\[|\\]|\\:\",\"\",str(columns_for_query))\n",
    "\n",
    "    #crear valores\n",
    "    values_for_query = str([tuple(i_value) for i_value in bq_csv_df.values.tolist()])\n",
    "    values_for_query = re.sub(\"\\[|\\]\",\"\",str(values_for_query))\n",
    "\n",
    "    #crear query\n",
    "    query = \"\"\"INSERT `{}.{}`({}) VALUES {}\"\"\".format(dataset_id,table_id,columns_for_query,values_for_query)\n",
    "    return query\n",
    "\n",
    "bq_query_insert_values = bq_query_insert_values(bq_csv_df,dataset_id,table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "811d3835-df59-494e-8bf9-57145ac15d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 Billing has not been enabled for this project. Enable billing at https://console.cloud.google.com/billing. DML queries are not allowed in the free tier. Set up a billing account to remove this restriction.\n",
      "\n",
      "Location: europe-southwest1\n",
      "Job ID: 949cd01c-0ffc-4689-9755-d61d506eaa23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bq_query_execution(client, bq_query_insert_values, dataset_id, table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bedc2c-dbf3-48c1-a874-6d6ae0e71964",
   "metadata": {},
   "source": [
    "###### * Si queremos eliminar los datos antes de insertarlos tendríamos que hacer un TRUNCATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2a82f868-928a-46ef-bc51-1ab45b2402b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_query_truncate_table(dataset_id,table_id):\n",
    "    query = \"\"\"TRUNCATE TABLE `{}.{}`\"\"\".format(dataset_id,table_id)\n",
    "    return query\n",
    "\n",
    "bq_query_truncate_table = bq_query_truncate_table(dataset_id,table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "06ecaac8-c9e3-4684-8d7e-639dd8e0a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 Billing has not been enabled for this project. Enable billing at https://console.cloud.google.com/billing. DML queries are not allowed in the free tier. Set up a billing account to remove this restriction.\n",
      "\n",
      "Location: europe-southwest1\n",
      "Job ID: 43b89f91-831d-46bd-8805-2e1d22c880d7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bq_query_execution(client, bq_query_truncate_table, dataset_id, table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226b815-99b2-419b-8444-2928e54de76d",
   "metadata": {},
   "source": [
    "##### b) python\n",
    "https://cloud.google.com/bigquery/docs/tables?hl=es-419"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df89869-5faf-487f-a83b-f54117bf177a",
   "metadata": {},
   "source": [
    "###### 1.A crear la tabla a mano si no existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b163040-3294-4d73-a30d-76257adf5e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test ya existe en el conjunto de datos chicago_taxi_tips.\n"
     ]
    }
   ],
   "source": [
    "# si quiero añadir particionar tablas:  https://cloud.google.com/bigquery/docs/creating-partitioned-tables?hl=es-419\n",
    "\n",
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'chicago_taxi_tips'\n",
    "table_id = 'cars_upload_test'\n",
    "\n",
    "try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(bq_credentials, scopes=scopes)\n",
    "    client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "except Exception as e:\n",
    "    print(\"Big query conection wrong: \" + str(e))\n",
    "\n",
    "try:\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "except Exception as e:\n",
    "    print(\"Error in Bigquery table reference: \" + str(e))\n",
    "\n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} ya existe en el conjunto de datos {dataset_id}.\")\n",
    "except Exception as e:\n",
    "    if \"Not found\" in str(e):\n",
    "        print(f\"La tabla {table_id} no existe en el conjunto de datos {dataset_id}.\")\n",
    "        # Crea la tabla si no existe\n",
    "        schema = [\n",
    "            bigquery.SchemaField(\"cars\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"mpg\", \"FLOAT\", mode=\"REQUIRED\"),\n",
    "            bigquery.SchemaField(\"cyl\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"disp\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"hp\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"drat\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"wt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"qsec\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"vs\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"am\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"gear\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"carb\", \"INTEGER\", mode=\"NULLABLE\")\n",
    "        ]\n",
    "        table = bigquery.Table(table_ref, schema=schema)\n",
    "\n",
    "        #para crear tabla particionada\n",
    "        #table.time_partitioning = bigquery.TimePartitioning(\n",
    "        #    type_=bigquery.TimePartitioningType.DAY,\n",
    "        #    field=\"date\",  # name of column to use for partitioning\n",
    "        #    expiration_ms=1000 * 60 * 60 * 24 * 90,\n",
    "        #)  # 90 days\n",
    "        \n",
    "        table = client.create_table(table)\n",
    "        print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n",
    "    else:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909c780-6e75-49f8-9a31-45d2f9e61bab",
   "metadata": {},
   "source": [
    "###### 1.B crear la tabla leyendo el schema del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f92349e-f889-4e3e-b224-9d91d4b9fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test no existe en el conjunto de datos chicago_taxi_tips.\n",
      "Created table curso-bigquery-mide-403114.chicago_taxi_tips.cars_upload_test\n"
     ]
    }
   ],
   "source": [
    "csv_path = './files/cars.csv'\n",
    "\n",
    "# Crea una instancia de la tabla en BigQuery (no la crea, solo define el esquema)\n",
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'chicago_taxi_tips'\n",
    "table_id = 'cars_upload_test'\n",
    "\n",
    "try:\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "except Exception as e:\n",
    "    print(\"Error in Bigquery table reference: \" + str(e))\n",
    "\n",
    "# Carga una muestra del CSV en un DataFrame de Pandas\n",
    "try:\n",
    "    sample_df = pd.read_csv(csv_path, sep=\",\")\n",
    "except Exception as e:\n",
    "    print(\"Error importing the csv file\" + str(e))\n",
    "# Crea un diccionario para almacenar el esquema inferido\n",
    "schema = {}\n",
    "\n",
    "# Itera sobre las columnas y determina el tipo de datos\n",
    "try:\n",
    "    for column in sample_df.columns:\n",
    "        # Infiera el tipo de datos basándose en los tipos de pandas\n",
    "        if pd.api.types.is_string_dtype(sample_df[column]):\n",
    "            schema[column] = 'STRING'\n",
    "        elif pd.api.types.is_numeric_dtype(sample_df[column]):\n",
    "            if pd.api.types.is_float_dtype(sample_df[column]):\n",
    "                schema[column] = 'FLOAT'\n",
    "            else:\n",
    "                schema[column] = 'INTEGER'\n",
    "        else:\n",
    "            schema[column] = 'STRING'  # Puedes ajustar según sea necesario\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# iterar este esquema para crear el formato qeu BQ necesita en un listado (ejemplo mas arriba en la creacion a mano del listado)\n",
    "try:\n",
    "    schema2=[bigquery.SchemaField(keyx, valuex, mode=\"NULLABLE\") for keyx,valuex in schema.items()]\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} ya existe en el conjunto de datos {dataset_id}.\")\n",
    "except Exception as e:\n",
    "    if \"Not found\" in str(e):\n",
    "        print(f\"La tabla {table_id} no existe en el conjunto de datos {dataset_id}.\")\n",
    "        \n",
    "        # Crea la tabla si no existe\n",
    "        table = bigquery.Table(table_ref, schema=schema2)\n",
    "\n",
    "        #para crear tabla particionada\n",
    "        #table.time_partitioning = bigquery.TimePartitioning(\n",
    "        #    type_=bigquery.TimePartitioningType.DAY,\n",
    "        #    field=\"date\",  # name of column to use for partitioning\n",
    "        #    expiration_ms=1000 * 60 * 60 * 24 * 90,\n",
    "        #)  # 90 days\n",
    "        \n",
    "        table = client.create_table(table)\n",
    "        print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d87eb6-f382-4a05-a093-9751674f2f40",
   "metadata": {},
   "source": [
    "###### 2.A INSERTAR datos del csv en la tabla debajo de los ya existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2c9bbcb-b645-46eb-8ec7-3041e0085d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test existe en el conjunto de datos chicago_taxi_tips.\n",
      "Datos del CSV cargados en la tabla cars_upload_test de BigQuery.\n"
     ]
    }
   ],
   "source": [
    "#cargar datos una vez que ya existe (los inserta debajo, si queremos sustituir, habrá que eliminarlos antes)\n",
    "csv_path ='./files/cars.csv'\n",
    "\n",
    "# Carga el CSV en un DataFrame de Pandas\n",
    "try:\n",
    "    df = pd.read_csv(csv_path, sep=\",\")\n",
    "except Exception as e:\n",
    "    print(\"Error importing the csv file\" + str(e))\n",
    "\n",
    "# Crea una instancia de la tabla en BigQuery (está hecho arriba, si lo hacemos junto habrá que eliminar las 2 siguientes lineas))\n",
    "try:\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table = bigquery.Table(table_ref)\n",
    "except Exception as e:\n",
    "    print(\"Error in Bigquery table reference: \" + str(e))\n",
    "\n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} existe en el conjunto de datos {dataset_id}.\")\n",
    "\n",
    "    job = client.load_table_from_dataframe(df, table)\n",
    "    job.result()  # Espera a que se complete la carga\n",
    "\n",
    "    print(f\"Datos del CSV cargados en la tabla {table_id} de BigQuery.\")\n",
    "except:\n",
    "    print(f\"La tabla {table_id} NO existe en el conjunto de datos {dataset_id}, hay que crearla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc4264-b0c5-495f-9aec-7725d824ddb1",
   "metadata": {},
   "source": [
    "###### 2.B REEMPLAZAR datos ya existentes en la tabla por los del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0b4ab0d-efb5-4ace-b715-95bc8e0de0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test existe en el conjunto de datos chicago_taxi_tips.\n",
      "Datos del CSV reemplazaron los existentes en la tabla cars_upload_test de BigQuery.\n"
     ]
    }
   ],
   "source": [
    "#cargar datos una vez que ya existe (los inserta debajo, si queremos sustituir, habrá que eliminarlos antes)\n",
    "csv_path ='./files/cars.csv'\n",
    "\n",
    "# Carga el CSV en un DataFrame de Pandas\n",
    "try:\n",
    "    df = pd.read_csv(csv_path, sep=\",\", index_col=False)\n",
    "except Exception as e:\n",
    "    print(\"Error importing the csv file\" + str(e))\n",
    "\n",
    "# Crea una instancia de la tabla en BigQuery (está hecho arriba, si lo hacemos junto habrá que eliminar las 2 siguientes lineas))\n",
    "try:\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table = bigquery.Table(table_ref)\n",
    "except Exception as e:\n",
    "    print(\"Error in Bigquery table reference: \" + str(e))\n",
    "\n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} existe en el conjunto de datos {dataset_id}.\")\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "    job = client.load_table_from_dataframe(df, table, job_config=job_config)\n",
    "    job.result()  # Espera a que se complete la carga\n",
    "\n",
    "    print(f\"Datos del CSV reemplazaron los existentes en la tabla {table_id} de BigQuery.\")\n",
    "\n",
    "except:\n",
    "    print(f\"La tabla {table_id} NO existe en el conjunto de datos {dataset_id}, hay que crearla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333458e-ed88-4cba-b9b0-888ee412b424",
   "metadata": {},
   "source": [
    "##### c) pandas_gbq  -> requiere autenticación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddaf21dc-d2e4-4160-898a-eaf51678b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla cars_upload_test ya existe en el conjunto de datos chicago_taxi_tips.\n"
     ]
    }
   ],
   "source": [
    "project_id = 'curso-bigquery-mide-403114'\n",
    "dataset_id = 'chicago_taxi_tips'\n",
    "table_id = 'cars_upload_test'\n",
    "\n",
    "try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(bq_credentials, scopes=scopes)\n",
    "    client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "except Exception as e:\n",
    "    print(\"Big query conection wrong: \" + str(e))\n",
    "\n",
    "# Ruta al archivo CSV en tu sistema local\n",
    "csv_path = './files/cars.csv'  # Reemplaza con tu ruta real\n",
    "\n",
    "# Verifica si la tabla existe en el conjunto de datos\n",
    "try:\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "except Exception as e:\n",
    "    print(\"Error in Bigquery table reference: \" + str(e))\n",
    "    \n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"La tabla {table_id} ya existe en el conjunto de datos {dataset_id}.\")\n",
    "except Exception as e:\n",
    "    if \"Not found\" in str(e):\n",
    "        print(f\"La tabla {table_id} no existe en el conjunto de datos {dataset_id}.\")\n",
    "\n",
    "        # Carga el CSV en un DataFrame de Pandas\n",
    "        df = pd.read_csv(csv_path, sep=\",\", index_col=False)\n",
    "\n",
    "        # Carga el DataFrame en BigQuery\n",
    "        to_gbq(df, f'{project_id}.{dataset_id}.{table_id}', project_id=project_id, if_exists='replace')\n",
    "\n",
    "        print(f\"La tabla {table_id} ha sido creada y los datos del CSV han sido cargados en BigQuery.\")\n",
    "    else:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87268d0-3c43-48f7-a9dc-9c5fc46ac52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
